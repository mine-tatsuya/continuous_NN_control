import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam, SGD

# 读取CSV文件，假设文件名为'xxx.csv'
# 第二列是x1，第三列是x2，第四列是y
data = pd.read_csv('simout2pfc.csv')

# 提取x1, x2, y，注意iloc函数从0开始检索
x1 = data.iloc[:, 5].values  # 第六列 (n-3)
x2 = data.iloc[:, 4].values  # 第五列 (n-2)
x3 = data.iloc[:, 3].values  # 第四列（n-1）
x4 = data.iloc[:, 2].values  # 第三列（n-0）
y = data.iloc[:, 1].values   # 第二列 (u)

# 将x1和x2合并为一个输入矩阵
X = np.column_stack((x1, x2, x3, x4))

# 构建模型
model = Sequential()

# 输入层到第一个隐藏层，30个神经元，激活函数为ReLU
model.add(Dense(30, input_dim=X.shape[1], activation='relu'))

# 第二个隐藏层，20个神经元
model.add(Dense(20, activation='relu'))

# 第三个隐藏层，10个神经元
model.add(Dense(10, activation='relu'))

# 输出层，假设输出是一个值
model.add(Dense(1, activation='linear'))

adam_optimizer = Adam(learning_rate=0.001)

# 编译模型，使用均方误差作为损失函数，Adam优化器
model.compile(optimizer=adam_optimizer, loss='mean_squared_error')

# 训练模型
model.fit(X, y, epochs=10, batch_size=32, verbose=1)

#sgdm_optimizer = SGD(learning_rate=0.001, momentum=0.9)
#model.compile(optimizer=sgdm_optimizer, loss='mean_squared_error')
#model.fit(X, y, epochs=5, batch_size=10, verbose=1)


# 将模型的权重保存到文本文件
with open('za2_model_weights.txt', 'w') as f:
    for layer_num, layer in enumerate(model.layers):
        weights = layer.get_weights()
        f.write(f'Layer {layer_num + 1} weights:\n')
        f.write(f'Weights: {weights[0]}\n')
        f.write(f'Biases: {weights[1]}\n\n')

print("1. 模型的权重已保存到 'pfcmodel_weights.txt'")

# 获取模型的所有权重和偏置
weights, biases = [], []
for layer in model.layers:
    weights.append(layer.get_weights()[0])
    biases.append(layer.get_weights()[1])

# 将权重和偏置保存到CSV文件
for i, (w, b) in enumerate(zip(weights, biases)):
    np.savetxt(f'z2pfc_weights_layer_{i}.csv', w, delimiter=',')
    np.savetxt(f'z2pfc_biases_layer_{i}.csv', b, delimiter=',')

print("2. 模型的权重已保存到各个CSV文件中")